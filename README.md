# OpenWeb UI with Ollama and CUDA Integration for Enhanced Performance

Pull and Run the Containers
```bash
docker-compose up -d
```

Go to ollama container

```bash
docker exec -it "container id" bash
```

Download LLM model from Ollama

```bash
ollama run gemma
/bye #exit
```




